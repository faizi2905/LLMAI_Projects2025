{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3836ec4-5d7c-4232-ae6c-727e537bce55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'llama3.2',\n",
       " 'message': [{'role': 'user', 'content': 'Tell me a fun fact!'}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "payload = {\n",
    "    \"model\" : \"llama3.2\",\n",
    "    \"message\" : [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\":\"Tell me a fun fact!\"}]\n",
    "}\n",
    "\n",
    "payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a27e2a09-c9e5-42f2-ae32-6144c3be2a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2', 'created_at': '2025-10-21T12:03:16.5433212Z', 'message': {'role': 'assistant', 'content': ''}, 'done': True, 'done_reason': 'load'}\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(\n",
    "    \"http://localhost:11434/api/chat\",\n",
    "    headers={\"Content-Type\": \"application/json\"},\n",
    "    json=payload\n",
    ")\n",
    "\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce059835-0c19-4555-9001-b48322b81e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's one:\n",
      "\n",
      "Did you know that honey never spoils? Archaeologists have found pots of honey in ancient Egyptian tombs that are over 3,000 years old and still perfectly edible! Honey's unique composition, with its low moisture content and acidic pH, makes it virtually impossible for bacteria or mold to grow. That's why bees have been making honey for millions of years, and it's likely to remain a tasty treat for centuries to come!\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(\n",
    "    model=\"llama3.2\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Tell me a fun fact\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response[\"message\"][\"content\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0bd22c-b278-4521-9b99-750e50d1f820",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
